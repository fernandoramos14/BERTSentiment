{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENTAL ANALYSIS - SPAM DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.8.1+cu111 (from versions: 2.0.0, 2.0.0+cpu, 2.0.0+cu117, 2.0.0+cu118, 2.0.1, 2.0.1+cpu, 2.0.1+cu117, 2.0.1+cu118, 2.1.0, 2.1.0+cpu, 2.1.0+cu118, 2.1.0+cu121, 2.1.1, 2.1.1+cpu, 2.1.1+cu118, 2.1.1+cu121, 2.1.2, 2.1.2+cpu, 2.1.2+cu118, 2.1.2+cu121, 2.2.0, 2.2.0+cpu, 2.2.0+cu118, 2.2.0+cu121, 2.2.1, 2.2.1+cpu, 2.2.1+cu118, 2.2.1+cu121, 2.2.2, 2.2.2+cpu, 2.2.2+cu118, 2.2.2+cu121, 2.3.0, 2.3.0+cpu, 2.3.0+cu118, 2.3.0+cu121, 2.3.1, 2.3.1+cpu, 2.3.1+cu118, 2.3.1+cu121, 2.4.0, 2.4.1, 2.5.0)\n",
      "ERROR: No matching distribution found for torch==1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\fernando\\anaconda3\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: requests in c:\\users\\fernando\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\fernando\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\fernando\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\fernando\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers requests beautifulsoup4 pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Encode and Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode('URGENT: Your account has been compromised. Verify your identity immediately.', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7315,  0.0907,  0.0408, -0.3277, -0.3396]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Go until jurong point, crazy.. Available only ...\n",
       "1                           Ok lar... Joking wif u oni...\n",
       "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       U dun say so early hor... U c already then say...\n",
       "4       Nah I don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    This is the 2nd time we have tried 2 contact u...\n",
       "5568                Will Ì_ b going to esplanade fr home?\n",
       "5569    Pity, * was in mood for that. So...any other s...\n",
       "5570    The guy did some bitching but I acted like i'd...\n",
       "5571                           Rofl. Its true to its name\n",
       "Name: v2, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/2024/NCI/Semester 3/Practicum 2/GitHub/LLM projects/Dataset/spam.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "#df = pd.DataFrame(np.array(reviews), columns=['review'])\n",
    "df[\"v2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v2'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(spam):\n",
    "    tokens = tokenizer.encode(spam, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score(df['v2'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512 take only the first 512 characters\n",
    "df['sentiment'] = df['v2'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  sentiment  \n",
       "0           NaN        NaN          1  \n",
       "1           NaN        NaN          3  \n",
       "2           NaN        NaN          4  \n",
       "3           NaN        NaN          1  \n",
       "4           NaN        NaN          3  \n",
       "...         ...        ...        ...  \n",
       "5567        NaN        NaN          1  \n",
       "5568        NaN        NaN          1  \n",
       "5569        NaN        NaN          2  \n",
       "5570        NaN        NaN          3  \n",
       "5571        NaN        NaN          5  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, å£1.50 to rcv\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v2'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1661 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  sentiment\n",
       "8     spam  WINNER!! As a valued network customer you have...          5\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...          5\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...          5\n",
       "13     ham  I've been searching for the right words to tha...          5\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!          5\n",
       "...    ...                                                ...        ...\n",
       "5550   ham        Cool, what time you think you can get here?          5\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...          5\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...          5\n",
       "5553   ham                        Hahaha..use your brain dear          5\n",
       "5571   ham                         Rofl. Its true to its name          5\n",
       "\n",
       "[1661 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_filtered_5 = df[df['sentiment'] == 5][['v1', 'v2', 'sentiment']]\n",
    "#df_filtered_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nuevo SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"sentiment.csv\")  \n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Extract BERT embeddings\n",
    "def sentiment_score(spam):\n",
    "    tokens = tokenizer.encode(spam, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1\n",
    "\n",
    "\n",
    "\n",
    "# Apply BERT embedding extraction to all rows\n",
    "df['bert_embedding'] = df['v2'].apply(get_bert_embedding)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(df['bert_embedding']),\n",
    "    df['sentiment'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train an SVM model on the BERT embeddings\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT 1ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'frombuffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3b21151f3fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Initialize BERT tokenizer and model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Function to generate embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python3.8\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3812\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mresolved_archive_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_add_variant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAFE_WEIGHTS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3813\u001b[0m                         \u001b[1;31m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3814\u001b[1;33m                         resolved_archive_file = cached_file(\n\u001b[0m\u001b[0;32m   3815\u001b[0m                             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3816\u001b[0m                             \u001b[0m_add_variant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSAFE_WEIGHTS_INDEX_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python3.8\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(checkpoint_file, is_quantized)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# Check format of the archive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"flax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mlx\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise OSError(\n",
      "\u001b[1;32mc:\\Python3.8\\lib\\site-packages\\safetensors\\torch.py\u001b[0m in \u001b[0;36mload_file\u001b[1;34m(filename, device)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msafe_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'frombuffer'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('D:/2024/NCI/Semester 3/Practicum 2/GitHub/BERT test/BERTSentiment/spam.csv',encoding = 'latin-1')\n",
    "\n",
    "\n",
    "# Check the data\n",
    "print(df.head())\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize and encode the text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Get the BERT output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Take the embedding of the [CLS] token\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return cls_embedding\n",
    "\n",
    "# Generate embeddings for each text in the dataframe\n",
    "df['embeddings'] = df['v2'].apply(get_bert_embeddings)\n",
    "\n",
    "# Example to see the embeddings\n",
    "print(df[['v2', 'embeddings']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/58/37166e7f71cd35e7f76d462fa058758a0aa6c31c1a7e26290f7898d37360/torch-2.4.1-cp38-cp38-win_amd64.whl\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=4.8.0 in c:\\python3.8\\lib\\site-packages (from torch) (4.12.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: torchvision 0.9.1+cu111 has requirement torch==1.8.1, but you'll have torch 2.4.1 which is incompatible.\n",
      "ERROR: torchaudio 0.8.1 has requirement torch==1.8.1, but you'll have torch 2.4.1 which is incompatible.\n",
      "  WARNING: The script isympy.exe is installed in 'c:\\Python3.8\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'c:\\Python3.8\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'C:\\\\Python3.8\\\\Lib\\\\site-packages\\\\~orch\\\\lib\\\\asmjit.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 19.2.3, however version 24.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: fsspec in c:\\python3.8\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in c:\\python3.8\\lib\\site-packages (from torch) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: filelock in c:\\python3.8\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/99/ff/c87e0622b1dadea79d2fb0b25ade9ed98954c9033722eb707053d310d4f3/sympy-1.13.3-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: networkx in c:\\python3.8\\lib\\site-packages (from torch) (2.5.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in c:\\python3.8\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in c:\\python3.8\\lib\\site-packages (from networkx->torch) (4.4.2)\n",
      "Installing collected packages: mpmath, sympy, torch\n",
      "  Found existing installation: torch 1.8.1+cu111\n",
      "    Uninstalling torch-1.8.1+cu111:\n",
      "      Successfully uninstalled torch-1.8.1+cu111\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached https://files.pythonhosted.org/packages/db/88/1ef8a624a33d7fe460a686b9e0194a7916320fc0d67d4e38e570beeac039/transformers-4.46.0-py3-none-any.whl\n",
      "Requirement already up-to-date: safetensors in c:\\python3.8\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\python3.8\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0,>=0.23.2 in c:\\python3.8\\lib\\site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in c:\\python3.8\\lib\\site-packages (from transformers) (1.24.4)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in c:\\python3.8\\lib\\site-packages (from transformers) (5.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Python3.8\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 19.2.3, however version 24.3.1 is available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in c:\\python3.8\\lib\\site-packages (from transformers) (4.61.0)\n",
      "Requirement already satisfied, skipping upgrade: filelock in c:\\python3.8\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied, skipping upgrade: tokenizers<0.21,>=0.20 in c:\\python3.8\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in c:\\python3.8\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in c:\\python3.8\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\python3.8\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in c:\\python3.8\\lib\\site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<3,>=2 in c:\\python3.8\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in c:\\python3.8\\lib\\site-packages (from requests->transformers) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=2023.5.0 in c:\\python3.8\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in c:\\python3.8\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in c:\\python3.8\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Installing collected packages: transformers\n",
      "  Found existing installation: transformers 4.45.2\n",
      "    Uninstalling transformers-4.45.2:\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "Successfully installed transformers-4.46.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers safetensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python3.8\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "                                                  v2  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                          embeddings  \n",
      "0  [tensor(-0.1513), tensor(-0.3229), tensor(0.18...  \n",
      "1  [tensor(-0.1238), tensor(0.3435), tensor(-0.00...  \n",
      "2  [tensor(-0.5031), tensor(-0.2829), tensor(0.57...  \n",
      "3  [tensor(0.0646), tensor(0.5769), tensor(0.3411...  \n",
      "4  [tensor(0.0947), tensor(0.3897), tensor(0.0389...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('D:/2024/NCI/Semester 3/Practicum 2/GitHub/BERT test/BERTSentiment/spam.csv',encoding = 'latin-1')\n",
    "\n",
    "\n",
    "# Check the data\n",
    "print(df.head())\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize and encode the text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Get the BERT output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Take the embedding of the [CLS] token\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    return cls_embedding\n",
    "\n",
    "# Generate embeddings for each text in the dataframe\n",
    "df['embeddings'] = df['v2'].apply(get_bert_embeddings)\n",
    "\n",
    "# Example to see the embeddings\n",
    "print(df[['v2', 'embeddings']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[tensor(-0.1513), tensor(-0.3229), tensor(0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[tensor(-0.1238), tensor(0.3435), tensor(-0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[tensor(-0.5031), tensor(-0.2829), tensor(0.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[tensor(0.0646), tensor(0.5769), tensor(0.3411...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[tensor(0.0947), tensor(0.3897), tensor(0.0389...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[tensor(-0.0725), tensor(0.0551), tensor(0.620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>[tensor(-0.0089), tensor(0.1375), tensor(0.270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>[tensor(-0.0464), tensor(0.0716), tensor(-0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>[tensor(0.2887), tensor(0.2153), tensor(-0.353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>[tensor(-0.6254), tensor(0.0154), tensor(0.062...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     v2  \\\n",
       "0     Go until jurong point, crazy.. Available only ...   \n",
       "1                         Ok lar... Joking wif u oni...   \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3     U dun say so early hor... U c already then say...   \n",
       "4     Nah I don't think he goes to usf, he lives aro...   \n",
       "...                                                 ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u...   \n",
       "5568              Will Ì_ b going to esplanade fr home?   \n",
       "5569  Pity, * was in mood for that. So...any other s...   \n",
       "5570  The guy did some bitching but I acted like i'd...   \n",
       "5571                         Rofl. Its true to its name   \n",
       "\n",
       "                                             embeddings  \n",
       "0     [tensor(-0.1513), tensor(-0.3229), tensor(0.18...  \n",
       "1     [tensor(-0.1238), tensor(0.3435), tensor(-0.00...  \n",
       "2     [tensor(-0.5031), tensor(-0.2829), tensor(0.57...  \n",
       "3     [tensor(0.0646), tensor(0.5769), tensor(0.3411...  \n",
       "4     [tensor(0.0947), tensor(0.3897), tensor(0.0389...  \n",
       "...                                                 ...  \n",
       "5567  [tensor(-0.0725), tensor(0.0551), tensor(0.620...  \n",
       "5568  [tensor(-0.0089), tensor(0.1375), tensor(0.270...  \n",
       "5569  [tensor(-0.0464), tensor(0.0716), tensor(-0.28...  \n",
       "5570  [tensor(0.2887), tensor(0.2153), tensor(-0.353...  \n",
       "5571  [tensor(-0.6254), tensor(0.0154), tensor(0.062...  \n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['v2', 'embeddings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.95      0.96      0.96       150\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.97      0.98      0.98      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert labels to numerical values (e.g., \"ham\" -> 0, \"spam\" -> 1)\n",
    "df['label'] = df['v1'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "\n",
    "# Convert embeddings to a 2D array format\n",
    "X = np.array([embedding.numpy() for embedding in df['embeddings']])\n",
    "y = df['label'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
